{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X data>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "x_train = pd.read_parquet(\"train_processed.parquet\")\n",
    "x_valid = pd.read_parquet(\"valid_processed.parquet\")\n",
    "x_test = pd.read_parquet(\"test_processed.parquet\")\n",
    "\n",
    "# Y data >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "y_train = pd.read_parquet(\"scaled_y_train.parquet\")\n",
    "y_valid = pd.read_parquet(\"scaled_y_valid.parquet\")\n",
    "y_test = pd.read_parquet(\"scaled_y_test.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor, ExtraTreesRegressor, RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error, explained_variance_score, mean_absolute_percentage_error\n",
    "from sklearn.svm import SVR\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.feature_selection import RFECV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = [XGBRegressor(),LGBMRegressor(),RandomForestRegressor()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfecv = RFECV(estimator=XGBRegressor(),min_features_to_select=10,scoring=\"r2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\v4run\\omdena\\phildelphia-10\\featureEngineering_RFE(Voting).ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/v4run/omdena/phildelphia-10/featureEngineering_RFE%28Voting%29.ipynb#ch0000005?line=0'>1</a>\u001b[0m _ \u001b[39m=\u001b[39m rfecv\u001b[39m.\u001b[39;49mfit(x_train,y_train)\n",
      "File \u001b[1;32mc:\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_rfe.py:710\u001b[0m, in \u001b[0;36mRFECV.fit\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m    707\u001b[0m     parallel \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_jobs)\n\u001b[0;32m    708\u001b[0m     func \u001b[39m=\u001b[39m delayed(_rfe_single_fit)\n\u001b[1;32m--> 710\u001b[0m scores \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    711\u001b[0m     func(rfe, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mestimator, X, y, train, test, scorer)\n\u001b[0;32m    712\u001b[0m     \u001b[39mfor\u001b[39;49;00m train, test \u001b[39min\u001b[39;49;00m cv\u001b[39m.\u001b[39;49msplit(X, y, groups)\n\u001b[0;32m    713\u001b[0m )\n\u001b[0;32m    715\u001b[0m scores \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(scores)\n\u001b[0;32m    716\u001b[0m scores_sum \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msum(scores, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_rfe.py:711\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    707\u001b[0m     parallel \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_jobs)\n\u001b[0;32m    708\u001b[0m     func \u001b[39m=\u001b[39m delayed(_rfe_single_fit)\n\u001b[0;32m    710\u001b[0m scores \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m--> 711\u001b[0m     func(rfe, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mestimator, X, y, train, test, scorer)\n\u001b[0;32m    712\u001b[0m     \u001b[39mfor\u001b[39;00m train, test \u001b[39min\u001b[39;00m cv\u001b[39m.\u001b[39msplit(X, y, groups)\n\u001b[0;32m    713\u001b[0m )\n\u001b[0;32m    715\u001b[0m scores \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(scores)\n\u001b[0;32m    716\u001b[0m scores_sum \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msum(scores, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_rfe.py:37\u001b[0m, in \u001b[0;36m_rfe_single_fit\u001b[1;34m(rfe, estimator, X, y, train, test, scorer)\u001b[0m\n\u001b[0;32m     35\u001b[0m X_train, y_train \u001b[39m=\u001b[39m _safe_split(estimator, X, y, train)\n\u001b[0;32m     36\u001b[0m X_test, y_test \u001b[39m=\u001b[39m _safe_split(estimator, X, y, test, train)\n\u001b[1;32m---> 37\u001b[0m \u001b[39mreturn\u001b[39;00m rfe\u001b[39m.\u001b[39;49m_fit(\n\u001b[0;32m     38\u001b[0m     X_train,\n\u001b[0;32m     39\u001b[0m     y_train,\n\u001b[0;32m     40\u001b[0m     \u001b[39mlambda\u001b[39;49;00m estimator, features: _score(\n\u001b[0;32m     41\u001b[0m         estimator, X_test[:, features], y_test, scorer\n\u001b[0;32m     42\u001b[0m     ),\n\u001b[0;32m     43\u001b[0m )\u001b[39m.\u001b[39mscores_\n",
      "File \u001b[1;32mc:\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_rfe.py:283\u001b[0m, in \u001b[0;36mRFE._fit\u001b[1;34m(self, X, y, step_score, **fit_params)\u001b[0m\n\u001b[0;32m    280\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    281\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mFitting estimator with \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m features.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m np\u001b[39m.\u001b[39msum(support_))\n\u001b[1;32m--> 283\u001b[0m estimator\u001b[39m.\u001b[39mfit(X[:, features], y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    285\u001b[0m \u001b[39m# Get importance and rank them\u001b[39;00m\n\u001b[0;32m    286\u001b[0m importances \u001b[39m=\u001b[39m _get_feature_importances(\n\u001b[0;32m    287\u001b[0m     estimator,\n\u001b[0;32m    288\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimportance_getter,\n\u001b[0;32m    289\u001b[0m     transform_func\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msquare\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    290\u001b[0m )\n",
      "File \u001b[1;32mc:\\Python39\\lib\\site-packages\\xgboost\\core.py:532\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[0;32m    531\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[1;32m--> 532\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Python39\\lib\\site-packages\\xgboost\\sklearn.py:961\u001b[0m, in \u001b[0;36mXGBModel.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m    956\u001b[0m     obj \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    958\u001b[0m model, metric, params, early_stopping_rounds, callbacks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_configure_fit(\n\u001b[0;32m    959\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[0;32m    960\u001b[0m )\n\u001b[1;32m--> 961\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_Booster \u001b[39m=\u001b[39m train(\n\u001b[0;32m    962\u001b[0m     params,\n\u001b[0;32m    963\u001b[0m     train_dmatrix,\n\u001b[0;32m    964\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_num_boosting_rounds(),\n\u001b[0;32m    965\u001b[0m     evals\u001b[39m=\u001b[39;49mevals,\n\u001b[0;32m    966\u001b[0m     early_stopping_rounds\u001b[39m=\u001b[39;49mearly_stopping_rounds,\n\u001b[0;32m    967\u001b[0m     evals_result\u001b[39m=\u001b[39;49mevals_result,\n\u001b[0;32m    968\u001b[0m     obj\u001b[39m=\u001b[39;49mobj,\n\u001b[0;32m    969\u001b[0m     custom_metric\u001b[39m=\u001b[39;49mmetric,\n\u001b[0;32m    970\u001b[0m     verbose_eval\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m    971\u001b[0m     xgb_model\u001b[39m=\u001b[39;49mmodel,\n\u001b[0;32m    972\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m    973\u001b[0m )\n\u001b[0;32m    975\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_evaluation_result(evals_result)\n\u001b[0;32m    976\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Python39\\lib\\site-packages\\xgboost\\core.py:532\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[0;32m    531\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[1;32m--> 532\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Python39\\lib\\site-packages\\xgboost\\training.py:181\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    180\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m--> 181\u001b[0m bst\u001b[39m.\u001b[39;49mupdate(dtrain, i, obj)\n\u001b[0;32m    182\u001b[0m \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    183\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python39\\lib\\site-packages\\xgboost\\core.py:1733\u001b[0m, in \u001b[0;36mBooster.update\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   1730\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_features(dtrain)\n\u001b[0;32m   1732\u001b[0m \u001b[39mif\u001b[39;00m fobj \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1733\u001b[0m     _check_call(_LIB\u001b[39m.\u001b[39;49mXGBoosterUpdateOneIter(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle,\n\u001b[0;32m   1734\u001b[0m                                             ctypes\u001b[39m.\u001b[39;49mc_int(iteration),\n\u001b[0;32m   1735\u001b[0m                                             dtrain\u001b[39m.\u001b[39;49mhandle))\n\u001b[0;32m   1736\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1737\u001b[0m     pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredict(dtrain, output_margin\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, training\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "_ = rfecv.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbmask = rfecv.support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgrfecv = RFECV(estimator=LGBMRegressor(),min_features_to_select=10,scoring=\"r2\",n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = lgrfecv.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbmask = lgrfecv.support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randrfecv = RFECV(estimator=DecisionTreeRegressor(),min_features_to_select=10,scoring=\"r2\",n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randmask = randrfecv.support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "votes = np.sum([xgbmask,lgbmask,randmask],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
